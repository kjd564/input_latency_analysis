<!DOCTYPE html>
<!--
Copyright 2016 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->

<link rel="import" href="/tracing/base/unit.html">
<link rel="import" href="/tracing/extras/chrome/cc/input_latency_async_slice.html">
<link rel="import" href="/tracing/model/async_slice_group.html">
<link rel="import" href="/tracing/model/event_set.html">
<link rel="import" href="/tracing/model/helpers/chrome_model_helper.html">
<link rel="import" href="/tracing/value/histogram.html">

<script>
'use strict';

tr.exportTo('pi.m', function() {

  // TODO(kdillon) : parameterize this mapper.
  var LATENCY_EVENT = 'GestureScrollUpdate';  // Latency event to be analyzed.
  var LATENCY_DURATION_THRESHOLD = 100;       // How long the latency event must take in ms.
  var UNINTERESTING_EVENTS = [                // Events to be ignored in the top down approach.
    'ChannelMojo::OnMessageReceived',
    'Event.Pipeline',
    'EventHandler::HitTestResultAtLocation',
    'FunctionCall',
    'LatencyInfo.Flow',
    'LocalFrameView::RunStyleAndLayoutLifecyclePhases',
    'LocalFrameView::updateStyleAndLayoutIfNeededRecursive',
    'LongTask',
    'MessageLoop::RunTask',
    'none',
    'PendingScript::ExecuteScriptBlock',
    'RenderWidgetInputHandler::OnHandleInputEvent',
    'RunTask',
    'ScheduledAction::execute',
    'SequenceManagerImpl::TakeTask',
    'TaskGraphRunner::RunTask',
    'TaskScheduler RunTask',
    'TaskQueueManager::DoWork',
    'TaskQueueManager::ProcessTaskFromWorkQueue',
    'TaskQueueManager::RunTask',
    'ThreadController::Task',
    'ThreadControllerImpl::DoWork',
    'ThreadControllerImpl::RunTask',
    'ThreadProxy::BeginMainFrame',
    'unknown interface',
    'WebViewImpl::beginFrame',
    'WebViewImpl::handleInputEvent',
  ];

  /**
  * Mapper to collect data on input latency events. This mapper looks at all of
  * the events that happened on the renderer during an input latency event in 
  * order to find which functions and callbacks contributed to the latency. The
  * output of the mapper is a JSON file containing information per trace:
  *
  * {
  *   "failures": [],
  *   "pairs": {
  *     "latencyEvents" : [ { latencyDuration : "..." , 
  *                           queueEventsBottomUp : [ ... ], 
  *		              handlingEventsBottomUp : [ ... ], 
  *		              queueEventsTopDown : [ ... ],
  *		              handlingEventsTopDown : [ ... ],
  *		              bottomUpEventSum : [ ... ],		      
  *		              topDownEventSum : } , ...
  *                       ],
  *     "metadata" : { "canonicalUrl" : "foo" }
  *   }
  * }
  */
  function inputLatencyMapper(result, model) {
    const results = [];
      
    const modelHelper = model.getOrCreateHelper(tr.model.helpers.ChromeModelHelper);
    const latencyEvents = getInputLatencyEvents(modelHelper.browserHelper);
      
    for (const latencyEvent of latencyEvents) {
      const data = latencyEvent.args.data;
      const id = (latencyEvent.id.startsWith(':ptr:') ? latencyEvent.id.slice(5) : latencyEvent.id);
      latencyEvent.id = id;
      const modelIndices = model.modelIndices;
      const flowEvents = modelIndices.getFlowEventsWithId(id);
	
      // Latency duration will be the time when the latency event is dispatched
      // to the renderer to when the rendering is scheduled.
      const latencyStart = (data) ? model.convertTimestampToModelTime(
          'traceEventClock',data['INPUT_EVENT_LATENCY_BEGIN_RWH_COMPONENT'].time) : 0;
      const handleStart = (data && data.hasOwnProperty('INPUT_EVENT_LATENCY_RENDERER_MAIN_COMPONENT')) ?
              model.convertTimestampToModelTime(
		  'traceEventClock',
		  data['INPUT_EVENT_LATENCY_RENDERER_MAIN_COMPONENT'].time) : 0;	
      const latencyEnd = getHandleInputEventMainCommitTime(flowEvents);
      const latencyDuration = latencyEnd - latencyStart;
	
      // Only look at completed latency events that are above the duration threshold.
      if (latencyEvent.inputLatency && latencyDuration >= LATENCY_DURATION_THRESHOLD && handleStart != 0) {
	const thread = getThreadByLatency(latencyEvent);
	const rendererEvents = thread.sliceGroup.slices;
        const topLevel = getTopLevelSlices(rendererEvents);
	  
	// Bottom-Up approach.
        // For each event happening during the latency, take the selfTime of the event
        // where the selfTime is the duration of the event minus the durations of its 
        // children. All events are split into a queuing and handling portion at the latency
        // mid point.
        const expandedEvents = [];
	const queue = [];
        const handle = [];
        expandTopLevel(topLevel, expandedEvents, latencyStart, latencyEnd);
	separateEvents(expandedEvents, queue, handle, latencyStart, latencyEnd, handleStart);
	  
	// Calculate renderer idle time which is the duration of the latency
	// where the renderer was not active at all.
	let queueActive = queue.reduce((prev,next) => prev + next['selfTime'],0);
	let handleActive = handle.reduce((prev,next) => prev + next['selfTime'],0);
	queue.push({'title': 'rendererIdle', 'selfTime': (handleStart - latencyStart) - queueActive});
        handle.push({'title': 'rendererIdle', 'selfTime': (latencyEnd - handleStart) - handleActive});

        // Top-Down approach.
        // Starting at the top level slices, traverse down the slice
        // stack until finding an event that is not on the interesting
        // event list. 
        const expandedEventsInteresting = [];
        const queueInteresting = [];
        const handleInteresting = [];
        expandTopLevelInteresting(topLevel, expandedEventsInteresting,latencyStart, latencyEnd, handleStart);
	separateEvents(expandedEventsInteresting, queueInteresting, handleInteresting,
		       latencyStart, latencyEnd, handleStart, 'Top-Down');

        // Add rendererIdle times, which are the same as the Bottom-Up approach.
	queueInteresting.push({'title': 'rendererIdle', 'duration': (handleStart - latencyStart) - queueActive});
        handleInteresting.push({'title': 'rendererIdle', 'duration': (latencyEnd - handleStart) - handleActive});
	 	  
        // Calculate interesting time, which is all unaccounted for time (total time minus the 
        // active time, which are the events we consider interesting plus the time spent idle, what
        // remains is the time spent in interesting tasks) 
	let queueActiveInteresting = queueInteresting.reduce((prev,next) => prev + next['duration'],0);
	let handleActiveInteresting = handleInteresting.reduce((prev,next) => prev + next['duration'],0);
        queueInteresting.push({'title': 'uninteresting',
				  'duration': (handleStart - latencyStart) - queueActiveInteresting});        
        handleInteresting.push({'title': 'uninteresting',
			        'duration': (latencyEnd - handleStart) - handleActiveInteresting});
	  
	results.push({'latencyDuration': latencyDuration,
		      'queueEventsBottomUp': mergeSameNameEvents(queue, 'selfTime'), 
		      'handlingEventsBottomUp': mergeSameNameEvents(handle, 'selfTime'),
		      'queueEventsTopDown': mergeSameNameEvents(queueInteresting), 
		      'handlingEventsTopDown': mergeSameNameEvents(handleInteresting),
		      'bottomUpEventSum': queue.reduce((prev,next) => prev + next['selfTime'],0) +
		      handle.reduce((prev,next) => prev + next['selfTime'],0),
		      'topDownEventSum': queueInteresting.reduce((prev,next) => prev + next['duration'],0) +
		      handleInteresting.reduce((prev,next) => prev + next['duration'],0)});
      }
    }
    result.addPair('latencyEvents', results);
    result.addPair('metadata', {'canonicalURL':model.canonicalUrl});
  }
  tr.mre.FunctionRegistry.register(inputLatencyMapper);

  return {
    inputLatencyMapper,
  };

  /**
  * Get all of the input latency event slices from this trace of a given latency
  * type (LATENCY_EVENT). 
  * @param {ChromeBrowserHelper} browserHelper
  * @return {Array<AsyncSlice>} Array of input latency event slices.
  */
  function getInputLatencyEvents(browserHelper) {
    const isInputLatencyEvent = e => e.title === 'InputLatency::' + LATENCY_EVENT;
    return browserHelper.getAllAsyncSlicesMatching(isInputLatencyEvent);
  }

  /**
  * Get the renderer thread that handled a given input latency event.
  * @param {AsyncSlice} latencyEvent
  * @return {Thread} model thread.
  */
  function getThreadByLatency(latencyEvent) {
    const associatedEvents = latencyEvent.associatedEvents;
    for (const event of associatedEvents) {
      if (event.title === 'RenderWidgetInputHandler::OnHandleInputEvent' &&
	  event.args.hasOwnProperty('event') &&
	  event.args.event === LATENCY_EVENT)	  
        return event.parentContainer;
    }
    assertUnreached("Failed to get thread that handled the latency event.");
  }

  /**
  * Find the flow event that tracks the handle input event main commit and return
  * it's end time. This will be used as the end of the latency event.
  * @param {Array<AsyncSlice>} flowEvents
  * @return {float} commitTime (ie end of commit) in ms.
  */
  function getHandleInputEventMainCommitTime(flowEvents) {
    for (const event of flowEvents) {
      if (event.args.step === 'HandleInputEventMainCommit') 
        return event.start + event.duration;
    }
  }
    
  /**
  * Takes an array of slices and returns all of the slices that are the topmost
  * slices (slices that have no parent slices).
  * @param {Array<AsyncSlice>} slices
  * @return {Array<AsyncSlice>} topLevel
  */
  function getTopLevelSlices(slices) {
    const topLevel = [];
    for (const slice of slices) {
	// If the slice is not already in the top level slices list and it is a top
	// slice, add it.
      if (typeof slice.mostTopLevelSlice !== 'undefined'
          && topLevel.indexOf(slice.mostTopLevelSlice) === -1) {
        topLevel.push(slice.mostTopLevelSlice);
      }
    }
    return topLevel;
  }
    
  /**
  * This function takes an array of top level slices and expands them, gathering
  * all of the children slices into a new array. It also truncates the slices so
  * that their durations fall within the bounds of the latency. 
  * @param {Array<AsyncSlice>} topLevelSlices
  * @param {Array<Object>} expanded This object is a shortened representation
  *     of an async slice containing the infromation relevant to the analysis.
  *     This array is populated as the function recurses. 
  * @param {float} start Measured in milliseconds.
  * @param {float} end Measured in milliseconds.
  */
  function expandTopLevel(topLevelSlices, expanded, start, end) {
    for (const topSlice of topLevelSlices) {
      if (topSlice.start < end && topSlice.end > start) {
        expanded.push({'title': topSlice.title, 'duration': topSlice.duration,
		       'selfTime': getSelfTime(topSlice, start, end), 
                       'start': topSlice.start,
		       'end': topSlice.start + topSlice.duration,
		       'subSlices': topSlice.subSlices});
      }
      expandTopLevel(topSlice.subSlices, expanded, start, end);
    }
  }

  /**
  * This function is the same as expandTopLevel but it traverses down the parent
  * slices until it finds a slice that is interesting, ie any slice that is not 
  * in UNINTERESTING_EVENTS, adds that slice to expanded, and stops moving down
  * the tree as opposed to adding all child slices.
  * @param {Array<AsyncSlice>} topLevelSlices
  * @param {Array<Object>} expanded This object is a shortened representation
  *     of an async slice containing the infromation relevant to the analysis.
  *     This array is populated as the function recurses. 
  * @param {float} start Measured in milliseconds.
  * @param {float} end Measured in milliseconds.
  * @param {float} handleStart Measured in milliseconds. Denotes when the 
  *     renderer began to handle the input.
  */
  function expandTopLevelInteresting(topLevelSlices, expanded, start, end, handleStart) {
    for (const topSlice of topLevelSlices) {
      addInterestingEvents(topSlice, expanded, start, end, handleStart);
    }
  }

  /**
  * This function recurses until it finds an interesting slice, calling 
  * expandTopLevelInteresting on a slices children if the slice itself is not 
  * intersting, and then adds those slices to expanded.
  * @param {Array<AsyncSlice>} topLevelSlices
  * @param {Array<Object>} expanded This object is a shortened representation
  *     of an async slice containing the infromation relevant to the analysis.
  *     This array is populated as the function recurses. 
  * @param {float} start Measured in milliseconds.
  * @param {float} end Measured in milliseconds.
  * @param {float} handleStart Measured in milliseconds. Denotes when the 
  *     renderer began to handle the input.
  */
  function addInterestingEvents(topSlice, expanded, start, end, handleStart) {
    if (UNINTERESTING_EVENTS.indexOf(topSlice.title) === -1) {
      if (topSlice.start < end && topSlice.end > start) {
	let sliceStart = Math.max(topSlice.start, start);
	let sliceEnd = Math.min(topSlice.end, end);
        expanded.push({'title': topSlice.title, 'duration': sliceEnd - sliceStart,
		       'start': sliceStart, 'end': sliceEnd});
      }
    } else {
      expandTopLevelInteresting(topSlice.subSlices, expanded, start, end, handleStart)
      return;
    }
  }

  /**
  * Calcuates a given slices self time which is the slices duration, bounded
  *     by the latency event, minus any child durations.
  * @param {AsyncSlice} slice
  * @param {float} start Measured in ms.
  * @param {float} end Measured in ms.
  * @return {float} the slices self time.
  */
  function getSelfTime(slice, start, end) {
    let childrenDuration = 0;
    for (const child of slice.subSlices) {
      if (child.start < end && child.end > start) {
        let childStart = Math.max(child.start, start);
	let childEnd = Math.min(child.end, end);
	if (childEnd > childStart)
          childrenDuration += childEnd - childStart;
      }
    }
    let sliceStart = Math.max(slice.start, start);
    let sliceEnd = Math.min(slice.end, end);
    return (sliceEnd - sliceStart) - childrenDuration;
  }

  /**
  * This function sorts a list of event objects into queuing and handling.
  * Queuing time is the time from the start of the latency to the middle, or when
  * the input is handled. Handling time is from the middle to the end. This 
  * breaks down a latency event events into these two categories.
  * @param {Array<Object>} events 
  * @param {Array<Object>} queue
  * @param {Array<Object>} handle
  * @param {float} start Measured in milliseconds.
  * @param {float} end Measured in milliseconds.
  * @param {float} handleStart Measured in milliseconds. Denotes when the 
  *     renderer began to handle the input.
  * @param {string} approach This string indicates which approach we are taking.
  *     Bottom-up looks at self times and Top-Down looks at duration.
  * @return {Thread} model thread.
  */
  function separateEvents(events, queue, handle,
			  start, end, handleStart, approach='Bottom-Up') {
    for (const event of events) {
      // Event is part of the queuing time
      if (event.end < handleStart) {
	queue.push(event);
      // Event is part of the handling time
      } else if (event.start >= handleStart) {
	handle.push(event);
      // Event is split between the two
      } else {
	var queuePortion = Object.assign({}, event);
	var handlePortion = Object.assign({}, event);  
	queuePortion.end = handleStart;
	handlePortion.start = handleStart;
	  
	if (approach === 'Top-Down') {
	  queuePortion.duration = handleStart - queuePortion.start;
	  handlePortion.duration = handlePortion.end - handleStart;
	} else {
	  queuePortion.selfTime = getSelfTime(queuePortion, start, handleStart);
	  handlePortion.selfTime = getSelfTime(handlePortion, handleStart, end);
	}
	queue.push(queuePortion);
	handle.push(handlePortion);
      }
    }
  }

  /**
  * For each latency event, merge all of the durations of events that have the
  * same name. This will give us the total time that any given function took 
  * over the course of the entire latency.
  * @param {Array<Object>} events
  * @return {Array<Object>} list of merged events.
  */
  function mergeSameNameEvents(events, duration = 'duration') {
    const merged = {};
    for (const event of events) {
      if (merged.hasOwnProperty(event.title)) {
        merged[event.title] += event[duration];
      } else {
        merged[event.title] = event[duration];
      }
    }
    return merged;
  }

  /**
  * Function for throwing error in the event that an assert fails.
  * @param {boolean} condition
  * @param {string} message
  */
  function assertUnreached(message) {
    throw new Error(message);
  }
});
</script>
